\section{Introduction and related work}

\begin{figure*}
	\includegraphics[width=\linewidth]{images/arch/vh-rm}

  \caption{Large data sets rendered with the \textit{Tuvok} framework.
  The Visible Human CT scan (a), the Wholebody data set (b) and a
  Richtmyer-Meshkov instability (c).}
	\label{fig:tvktease}
\end{figure*}

In the past decade texture-based volume rendering on graphics hardware
has positioned itself as a powerful tool for interactive visual
analysis of modestly sized data sets. In earlier years slice-based
approaches~\cite{Cullip:1993:AVRW, Cabral:1994:AVRA} were utilized
due to the limited capabilities of older graphics hardware, with the
drawback of distracting visual artifacts. Later, GPU-based ray casting
became possible on consumer GPUs, producing superior image quality
and allowing for the integration of various acceleration
strategies~\cite{Krueger:2003:ATGV}.  In addition to improvements in
volume traversal methods, various approaches have been presented to
efficiently render data larger than the video or even the system's main
memory.

As data sizes grow, however, an efficient rendering system only solves
part of the visualization problem. Along a different line of research,
novel methods have been proposed to effectively interrogate, search,
highlight and present data with an increasing number of high resolution
features. In the course of this research multi
dimensional-~\cite{Kniss:2005:Multidim}
spatialized-~\cite{Roettger:2005:Spatialized},
size-based-~\cite{Correa:2008:Size-based}, motion
controlled-~\cite{Correa:2005:Motion},
topology-based~\cite{Weber:2007:Topology},
and style transfer functions~\cite{Bruckner:2007:Style}, as well as
other focus and context enhancing
techniques~\cite{Viola:2005:Illustrative, Wang:2005:Lens,
Krueger:2006:ClearView} have been developed. For a complete and
detailed survey on volume rendering we refer the reader to the state of
the art report, course, and books by Engel et
al.~\cite{Engel:2002:IHQV, Engel:2004:RTVG, Engel:2006:RTVG}.

Due to this vast body of research a large variety of different volume
rendering systems and prototypes exist both in academia as well as
in industry. Yet researchers and developers often reimplement the
same basic fundamentals for each new volume rendering application. It
may seem that there are many different good reasons for not reusing
existing, proven code, but one can usually categorize the decision into
one of three cases:

\begin{itemize}

  \item \textbf{System}:
	Often, the integration of new ideas and methods
	into large monolithic rendering systems proves to be a
	bigger issue than re-implementing the entire environment
	from scratch.

  \item \textbf{Software Environment}: The existing code may be
  implemented in the wrong environment, such as for an old operating
  system or graphics API. For instance, a DirectX implementation will
  not be suitable for a cross platform project. Further, many research
  prototypes are tailor-made for one system due to the lack of time and
  need for a more general implementation.

  \item \textbf{Licensing}: while largely irrelevant in the academic
  environment, license issues often prevent developers in commercial
  environments from reusing existing code. Even code that is released
  under Open Source conditions may come with untenable requirements,
  such as the GPL's stipulation that related yet non-derivative code be
  released under the GNU license.

\end{itemize}

Research groups and companies often release their work and thus a
number of systems for volume rendering structured data exist as free
or open source programs. One of the earliest examples of such an
open source volume rendering system is Stanford's VolPack
software~\cite{VolPack}.  Unfortunately it has not been under
development for two decades. A more recent example is the Simian system
developed
by Kniss \textit{et al}~\cite{Simian}. Released under a very liberal
open source license, it features both a very polished user interface as
well as multi-dimensional transfer function support. Unfortunately it
falls short as far as data import is concerned and development ceased
years ago; therefore no novel render modes are implemented. Other such
discontinued frameworks and toolkits are the OGLE~\cite{OGLE} system,
optimized for large data, and OpenQVis~\cite{OpenQVis}, optimized for fast GPU
rendering. A program tailored for 3D Microscopy,
Voxx~\cite{Indiana:2009:Voxx}, has been released by Indiana University;
while it has very promising features, including support for 4D data,
it is only published in binary form.  While Bruckner and Gr\"oller's
`volumeshop'~\cite{Bruckner:2005:VolumeShop} implements unique GPU
accelerated illustrative render options, its development ceased in 2005
and no current version is available. Further, it only supported their
proprietary volume format and the current license disallows the use of
the code in commercial environments.

For medical applications the MITK toolkit~\cite{Tian:2008:MITK}
delivers many interesting features, including support for large data
sets and data manipulation routines, but it offers only basic transfer
function support and slow performance compared to highly optimized
out-of-core GPU volume rendering systems. Solely on the Apple Mac
OS X platform, OsiriX~\cite{OsiriX} offers unmatched DICOM support in
an open source application, but as the tool is tied closely to Apple's
Cocoa framework and implemented in Apple-extended Objective-C, it is
nigh-impossible to port to any other platform.

Instead of using a specialized volume rendering application,
existing visualization toolkits can be utilized to render
volumetric data. The most prominent examples are the
VTK~\cite{Schroeder:2006:VTK} and ITK \todo{[YAL02]} systems, which allow
for extremely versatile and flexible rendering and modification
of many types of data sets. The major drawback is
the lack of support for out-of-core processing, forcing
application developers to concoct external strategies to handle
large data sets. The ParaView application~\cite{Ahrens:2005:ParaView},
built on top of VTK, addresses this issue and extends the support
to large data sets but---like the underlying toolkit---does not
efficiently utilize the capabilities of modern graphics cards,
resulting in interactive performance only at very low quality even for
modestly sized data sets. Recently, the VisCG at the Universit\"at
M\"unster developed the Voreen
system~\cite{Voreen:2009}, a prototyping environment for volume
visualization.  The interface provided exposes the underlying data
flow network and many visualizations require knowledge as to how
they are technically realized, which we found was not suitable for a
large segment of our user base. Other non commercial visualization
toolkits are the OpenDX3 \todo{[IBM06]} system which is no longer under active
development, and
finally the SCIRun \todo{[Ins09]} and VisIt~\cite{Childs:2005:Contracts,
Childs:2012:VisIt} systems. As these systems suffered some of the
problems of previously mentioned solutions (e.g. outdated render modes,
slow performance, or limited support for large data sets) Tuvok is
currently being integrated into these solutions. Besides these free
\& open source solutions, a number of commercial products exist such
as AVS2, Amira, Ensight, syngo, VGStudio Max, or AltaViewer. As these
systems are closed source, obtaining detailed information on their
operation is difficult; the possibility of integrating Tuvok into these
systems is intriguing, but we do not discuss them in detail for this
work.

In order to address the aforementioned three issues and to overcome the
limitations of existing systems, we present \textit{Tuvok}, a system
built of cleanly separated components that can
be used together, such as in the \textit{ImageVis3D} application,
or stand-alone. The entire system is implemented in C++ with OpenGL
graphics and is designed to be completely platform independent. When
necessary, Tuvok's components can be compiled into a shared library
and accessed from another programming language. Tuvok is also released
with a modest open source license that allows unrestricted academic and
commercial use of the code. Specifically,
\textit{Tuvok} offers the following benefits:

\begin{enumerate}

\item \textbf{Large Data Support}
Given sufficient storage space, the system can theoretically
handle data sets of up to 16 Exabytes in size.
\item \textbf{Modular Design}
While the application ImageVis3D presents itself to the
end-user as a single application, it is composed of a
collection of independent Tuvok frameworks.
\item \textbf{Self contained}
While ImageVis3D requires Nokia's Qt \todo{[Nok09]} library
as an external dependency, \textit{Tuvok} itself does not rely on
external libraries at all.
\item \textbf{Cross platform support}
\textit{Tuvok} as well as \textit{ImageVis3D} support all major platforms,
including various versions of Microsoft Windows, Apple
Mac OS X, and many Linux variants.
\item \textbf{Legacy hardware support}
Tuvok has been extensively tested to work even with the
very limited GPU capabilities of older or less capable
systems.
\item \textbf{Up To Date Rendering algorithms}
Besides its support for 2D and 3D texture based slice
based volume rendering---mostly for older graphics
hardware---\textit{Tuvok} features GPU based ray casting to
interactively render images of the highest quality.
\item \textbf{Provenance Support}
\textit{Tuvok} and \textit{ImageVis3D} provide provenance hooks, with
provenance recording and playback realized via VisTrails
\todo{[BCS 05]}.
\item \textbf{Open Source}
Tuvok and ImageVis3D are released under the very liberal
MIT license, which means that practically no usage
restrictions exist---including the use of ImageVis3D or its
components in commercial applications.

\end{enumerate}

The remainder of this chapter is organized as follows. In
Section~\ref{sec:tvk-design} we discuss the design of \textit{Tuvok},
focusing on the ways in which the library handles large data. To
demonstrate
the versatility of \textit{Tuvok} and \textit{ImageVis3D}, we describe
extensions
to the system in Section~\ref{sec:tvk-extensions}, and projects that
have
incorporated \textit{Tuvok} in Section~\ref{sec:tvk-uses}. We conclude
with a summary of the presented system and future research directions.

\section{Design}
\label{sec:tvk-design}

The ImageVis3D system is composed of three major
components, the Tuvok Volume rendering library, the Tuvok IO
library, and the Qt based UI toolkit. Note that these
components are designed to work well together but can also be
used separately or replaced by other external libraries (see
Section~\ref{sec:tvk-uses} for examples). In fact, during the
compilation process of Tuvok the subcomponents are compiled as separate
libraries that are simply linked together. During the design of these
components care has been taken to create flexible and simple interfaces
between the subcomponents. As an example of this decoupled design,
the communication from the UI to the rendering and IO systems happens
through a single entity, named the \texttt{MasterController}. This concept makes
it easy to intercept all the communication to and from the
UI (see Section~\ref{sec:tvk-extensions}) and is also the heart of the
scripting interface built into ImageVis3D, which allows programmatic
control over the application.

\subsection{The volume rendering library}

The Tuvok volume rendering library contains the core graphics
algorithms to render volumetric data. Currently, a slice
based volume renderer as well as GPU based ray casting
renderer are available in OpenGL and DirectX 10. For pure
software based rendering the system currently relies on the
Mesa library \todo{[Pau]}.

\subsection{Interactivity and quality}

One of the primary design goals of Tuvok is that it should be able
to visualize data sets of incredible size on almost any commodity
system. We have previously scaled the renderer to
data sizes greater than 2 terabytes~\cite{Fogal:2010:HPG}, including
the 5
terabyte rabbit eye from Figure~\ref{fig:rabbit5tb}.

This is achieved using a streaming, progressive rendering
system guaranteeing interactive frame rates with adaptive
quality. The generation of full quality imagery is also
guaranteed on all configurations, with any data set, but may not
happen interactively.

To achieve this goal Tuvok utilizes a multiresolution level of detail
(LoD) data representation. It queries the volume parameters from the
Tuvok IO Library---or an external IO framework through a documented
API if the IO library is not used---and uses that information together
with the current viewing parameters and system performance history to
compute a work order for the current render task. More
details are available in Section~\ref{sec:tvk-data}.

To achieve goals 4-6 in the list above, renderers contain a variety of
extra code paths for compatibility settings, as a means to address a
number of issues discovered in OpenGL drivers. Tuvok contains multiple
renderers, based on ray casting, 3D slicing, and 2D slicing, which span
a large range of quality versus portability across GPUs and drivers.
This has been important to support a breadth of collaborations, as
less technical users tend to have integrated graphics chips that
lack support for even 3D textures. One feature driven by this
requirement is the ability to select the bit width of the framebuffer
object (FBO) used for rendering, because we found that some drivers
would switch to a software path when rendering into a 32-bit FBO.

Table 1 gives timings for multiple data sets on different
systems, demonstrating the system's compatibility and scalability.
For these timings the progressive rendering has been
disabled: only the time to render the maximum quality
image for the given view was measured. With the progressive
rendering turned on all data sets render at the chosen refresh
rates on all systems. Note that the systems used in the test
cover chipset integrated GPUs as well as also high end PC
configurations. Timings are presented for small data sets as
well as reasonably sized CT scans and simulations. Using
even larger data sets does not significantly impact the
performance of the system, as the amount of data accessed is
bounded by the screen resolution.

\begin{table}
	\begin{tabular}{l|c|c|c}
	data set & Air & Pro & Vista \\\hline

	\begin{minipage}{0.4\linewidth}
	\textbf{C60 Molecule}\\128x128x128 8bit = 2 MB\\See	Figure~\ref{fig:modes}
	\end{minipage}
	& 110 / 184 & 80 / 124 & 12 / 14\\\hline

	\begin{minipage}{0.4\linewidth}
	\textbf{VH Male CT}\\512x512x1884 8bit = 471 MB\\See
	Figure~\ref{fig:tvktease}a
	\end{minipage} & 380 / 500 & 526 / 744 & 48 / 76\\\hline

	\begin{minipage}{0.4\linewidth}
	\textbf{Wholebody}\\512x512x3172 16bit = 1586 MB\\See
	Figure~\ref{fig:tvktease}b
	\end{minipage} & 680 / 700 & 587 / 984 & 126 / 301\\\hline

	\begin{minipage}{0.4\linewidth}
	\textbf{RM Instability}\\2048x2048x1920 8bit = 7680 MB\\See
	Figure~\ref{fig:tvktease}c
	\end{minipage} & 5523 / 6112 & 3112 / 3520 & 196 / 321 \\

	\end{tabular}

  \caption{Tuvok timings in \textbf{milliseconds} for various data sets
  and configurations.  ``Air'': MacBook Air, 2GB RAM, onboard GeForce
  9400, ``Pro'': MacBook Pro, 4GB RAM, GeForce 9600, ``Vista'': PC
  running windows Vista, 24 GB RAM, Quadro 5800.  All tests were
  performed in isosurface mode (first value) and in 1D transfer
  function mode (second value), using the ray casting renderer and
  sampling twice per voxel into a 1024x1024 viewport.  The camera was
  zoomed such that the data set covered the entire viewport, and the
  datasets were divided into bricks of size $256^3$.}

\end{table}

\begin{figure*}
	\includegraphics[width=\linewidth]{images/arch/c60modes}

  \caption{Various render modes applied to the C60 dataset.  In the
  top row 1D and 2D transfer functions, isosurface extraction, and
  ClearView are shown.  The bottom row shows the same views in anaglyph
  stereo mode.  On the right is two by two mode featuring a 3D view, a
  MIP view (top right) and two slice views (bottom).}
	\label{fig:modes}

\end{figure*}

\subsection{Large scale data handling}
\label{sec:tvk-data}

While Tuvok can take advantage of recent advances in hardware
capabilities, it is still true that data are growing and have been
growing faster than hardware capabilities allow. Thus, while the size
of data sets that we can interactively render is increasing with each
hardware revision, we still find that a larger percentage of our data
sets cannot be rendered interactively.  It would be unreasonable to
assume this trend would reverse in the coming years. Therefore, it is
critical that interactive visualization systems incorporate progressive
renderers.

Tuvok's progressive renderer is based on overloaded
concepts of frames and subframes. In the context of Tuvok, a
frame is a single, complete rendering of the data at native
screen and data resolution. A subframe is an intermediate
state between no rendering and a frame, which includes the
full spatial range of the data and any annotations present in
the visualization. The quality of successive subframes
monotonically increases. A sequence of these subframes are
rendered before the final frame is displayed, detailing different
approximations of the complete rendering much more
quickly than a frame can be displayed. We guarantee that
there is always at least one subframe which can be displayed
interactively (within a couple hundred milliseconds). The
system turns to such a subframe when the user is actively
interacting with the data.

To model the concepts of frames and subframes, Tuvok
uses a multiresolution, level of detail representation of data.
For the most part, a subframe corresponds to the data at
a particular level of detail. At the coarsest level of detail,
the data are small enough that they can easily be read from
disk under our real time requirements. However, we found
that older GPUs could not always render such data quickly
enough for our needs. Therefore Tuvok always makes available
up to three additional subframes. These are generated
by lowering the screen resolution of the rendering (and upscaling
before display to the user), lowering the sampling
rate used by the renderer, or both. Lowering resolution and
sample rate significantly reduces the strain on the fragment
processing stage of the graphics pipeline, allowing Tuvok
to respond quickly even on low end hardware. We do not
know any OpenGL 2.0-capable GPU which Tuvok does not
perform acceptably on, and (through extensions) Tuvok can
render even on some cards that do not report OpenGL 2.0
capabilities.

\subsubsection{Preprocessing}

Most data are not fed to visualization software with multiple
levels of detail included. To accommodate such data, Tuvok's IO
subsystem implements a preprocess which generates a multiresolution
hierarchy. The data at their native resolution form the finest level
of detail, and we subsample by two recursively until a level of detail
exists which is less than or equal to a predefined user-configured
limit. We also use this opportunity to perform other operations on
the data, such as ensuring a consistent endianness.  In most cases
preprocessed data can be loaded from disk directly into GPU memory.

The primary issues we face when loading large data are
32-bit address spaces, limitations on GPU 3D texture sizes,
and managing the IO in an efficient manner. The address
space limits us to only handling two gigabytes of data at any
one time. Limitations on texture sizes prevent us from `simply'
loading the data into a single, large 3D texture. Typical
IO performance on desktop-class and predicted future hardware
informs our strategy for how we access and consume
data.

To tackle these issues, the preprocess divides each level of
detail into a set of bricks, with each brick small enough to fit
into the texture memory of any modern GPU. The rendering
core will render each level of detail in an out-of-core fashion:
a brick will be loaded, rendered, and discarded as a single
atomic operation. This allows the renderer to load data of
virtually unlimited size with very little available memory, as
the required amount of memory is independent of the data
set size. To achieve the IO performance we require, the IO
library uses large reads (by default, 16 megabytes) that make
seek times virtually irrelevant.

A simple survey of modern disk drives finds reported seek
times ranging from 3.75 up to 8.9 milliseconds. Sustained
transfer rate capabilities can be as low as 65 MB/s; see
Table~\ref{tbl:disks}.  While there are of course differences across
drives and manufacturers, multi-megabyte reads very quickly overtake
seek times as the predominant factor in disk transfers. At 65 MB/s,
it takes almost a quarter of a second to read 16 megabytes of data,
yet only 8 milliseconds to seek to the position of that block. Even as
one gets into the higher end drives, the story is the same; a Cheetah
15K.5 would take 0.12 seconds to read a 16 megabyte chunk of data, and
only 3.75 milliseconds to seek to the appropriate location on disk.
In relative terms, seek time makes up approximately 3\% of the time
required to read the data block. Based on these simple calculations, it
is clear that transfer rates will have to improve drastically before
seek times become a relevant parameter.

\begin{table}
	\begin{center}
	\begin{tabular}{l|cc}
	\textbf{Drive name} & \textbf{Seek time (ms)} &
		\textbf{Sustained transfer rate (MB/s)}\\\hline
	Cheetah 15K.5 SAS & 3.75 & 73 to 125\\
	WD Caviar RE2-GP & 8.9 & 84\\
	Barracuda 7200.8 & 8 & 65\\
	WD 740GD & 5.2 & 72\\
	\end{tabular}
	\end{center}

	% note to self: you already updated the year, here, for your dissertation!
  \caption{Relevant disk performance characteristics for disks ranging
  from high-end server drives (Cheetah 15K.5) to an aging model
  released 11 years ago (WD 740 GD)}
	\label{tbl:disks}
\end{table}

We have also benchmarked our I/O subsystem using solid
state drives. Table~\ref{tbl:ssd} shows the time spent on I/O when
loading a 648-brick data set via Tuvok. The SSD boasts vastly better
seek times, on the order of microseconds instead of the normal
milliseconds for mechanical drives, and a factor of two to three
improvement in bandwidth. Using large reads, the seek time matters
little in this case, but as shown in Table~\ref{tbl:ssd} Tuvok benefits
from the improved transfer times offered by SSDs.

\begin{table}
	\begin{center}
	\begin{tabular}{|c|c|}\hline
	\textbf{3-disk SATA RAID5} & \textbf{Solid state drive}\\\hline
	64.8704 & 27.6723\\\hline
	\end{tabular}
	\end{center}

  \caption{I/O component (seconds) for rendering a 9 gigabyte timestep
  from a simulation of a Richtmyer-Meshkov instability.}
	\label{tbl:ssd}
\end{table}

\subsubsection{Paging strategy}

Transfer time forms the majority of our pipeline execution time when
using high end GPUs. Therefore, by maintaining a cache for individual
bricks, we can improve the overall rendering time by obviating the
transfer time for oft-requested bricks.

A straightforward paging strategy for such a cache would
be Least Recently Used (LRU), however this strategy delivers
poor performance in many situations. Consider a dataset
with 10 bricks, and a brick cache capable of storing 9 bricks.
In the first frame, all ten bricks must be paged. Further, loading
the final brick of the first frame will evict the first brick
of that frame. Assuming any reasonable amount of frame-to-frame
coherence, the next frame will again need the same 10
bricks, and they are likely to require a similar depth ordering.
Thus, in the second frame, the first brick we will need
is the brick we just evicted at the end of the last frame; further,
the second brick we need will be evicted while loading
the first brick of the second frame, and so on throughout the
entire frame.

We have implemented a custom paging strategy that
takes into account our progressive rendering system. In this
strategy, we evict bricks \emph{within} a frame using the Most Recently
Used (MRU) strategy; we evict bricks \emph{between} frames using the
LRU strategy. The rationale for the former is that once we have used a
brick in a subframe, it will not be used in the rendering of that frame
again until the progressive renderer starts over, and we may service
a large number of bricks in the interim. However, if we do start the
frame from its earliest subframe again, particularly before finishing
the frame, we are likely to need the oldest bricks which are present
in the cache. Between frames, we rely on frame-to-frame coherence. If
a brick was not used in the previous frame, and is not used in the
current frame, it is likely to not be required in subsequent frames as
well; a common example is if the user has enabled a clip plane: any
viewing transform will not affect the bricks that are clipped away by
the plane. Therefore the LRU strategy will tend to evict bricks that
are not visible under the current transfer function, isosurface, or
viewing parameters.

\subsection{UI and networking library}

To facilitate rapid development of other visualization applications,
all those components built on top of Qt which are
not specific to the application level were separated, allowing
them to be shared and reused in future applications. These
components can be roughly categorized as the UI and networking
components. The independent networking components
include the bug reporting, update checking, and data
set sharing subsystems, while the UI components include
the base classes that define the look and feel of ImageVis3D,
such as dialogs, tool widgets, user interaction, and persistence.

\section{Extensions to \textit{Tuvok} and \textit{ImageVis3D}}
\label{sec:tvk-extensions}

In this section we present a couple of examples to
demonstrate how simple it is to add new features or extend
existing functionality. We present examples from research
projects implementing a prototypic environment to experiment
with new methods (\tjfsec{sec:arch-rendering-exts}) as well as new
features to ImageVis3D to use it for other research.

Due to the modular design, the scripting interface, and
the \texttt{MasterController} concept, integration with external
software is simple. As the UI and execution layer communicate
strictly through a single class, the \texttt{MasterController}, any
type of external communication channel can simply attach
itself to this class and track changes. Control of the library
can also happen through the \texttt{MasterController} via script
commands that allow programmatic modification of all of
Tuvok's features.

\subsection{Extensions to the rendering subsystem}
\label{sec:arch-rendering-exts}

ImageVis3D has been extended to provide domain specific
visualization capabilities. In some domains, it is necessary
to visualize multiple data sets simultaneously. A student has
modified ImageVis3D to render multiple data sets that live in
overlapping space, and added domain-specific widgets for
ease of use in a particular scientific domain. One such example
is a dialog to automatically create transfer functions,
based on external knowledge of characteristic data distributions
within data sets common to that field. A second example
is repurposing the 2D transfer function editor to utilize
different metadata along each axis.

\subsection{Extensions to \textit{Tuvok}'s controller}

For provenance tracking, we have integrated VisTrails, a production
provenance framework with well-developed APIs
for integration with external systems. The integration of
VisTrail’s provenance tracking features required a two way
communication from and to Tuvok. Interactions made by
the user need to be communicated to VisTrails to track the
provenance, but also VisTrails needs to be able to control Tuvok
to perform undo/redo operations. Thus, this example is
prototypic for any type of recording or remote control of Tuvok,
such as cluster extensions or connections to novel input
devices.

\section{Use cases of \textit{Tuvok}}
\label{sec:tvk-uses}

\begin{figure*}
	\includegraphics[width=\linewidth]{images/arch/integration}

  \caption{3D texture, SLIVR, and \textit{Tuvok} volume renderers in
  VisIt (left); \textit{Tuvok} rendering a torso in SCIRun (right).}
	\label{fig:integration}
\end{figure*}

In the following we present examples where Tuvok---or only some of it
components---have been integrated into rendering environments other
than
\textit{ImageVis3D}. Figures~\ref{fig:integration}
and~\ref{fig:altaviewer} demonstrate the integrations presented here.

\subsection{SCIRun}

SCIRun is a problem solving environment for modeling,
simulation, and visualization of scientific data. It is an example
of what we refer to as a legacy application, in that it
was developed without the ideas implemented by Tuvok in
mind. In particular, this means that the system must work
with in-core, `unbricked' data sets of a single resolution.

To support such an environment, Tuvok has a simplified
API for existing systems which do not include level of detail
or bricking concepts. The information flows one way from
the controlling application to Tuvok, and includes a reference
counted smart pointer to the data, as well as metadata
and rendering parameters. For small changes in rendering
parameters, data shared from previous frames is retained and
simply re-rendered. When changing or passing a new data
set to Tuvok, the old data set is removed and replaced by
a new reference counted smart pointer. This scheme allows
us to avoid data copying between the host application and
rendering library. In these kinds of systems, Tuvok does not
have access to a multiresolution form of the data, and thus
cannot guarantee interactive performance.

\subsection{VisIt}

VisIt is a data visualization and analysis application which is
well-suited to large scale data processing on leadership computing
platforms. We have integrated the underlying rendering
core as an option alongside VisIt's existing volume renderers.
Since VisIt already supported domain-based data set
decomposition, it can easily take advantage of an additional
Tuvok feature: bricking. This allows VisIt to volume render
data of arbitrary size on the GPU, whereas it was previously
limited to resampling the data or utilizing software rendering.

Though data do not come directly from a data file in this
and other integration work, the abstraction provided by Tuvok's
IO layer allows the rendering core to remain ignorant
about the source of the data. The metadata which must be
supplied to Tuvok scales with the complexity of the application:
in the unbricked, SCIRun case, Tuvok can be told only
the brick size (assuming the brick lies centered on the origin);
with decomposed data, Tuvok must be informed of the
world space location of the bricks; for progressive rendering
applications, such as ImageVis3D, the LoD that a brick belongs
to must also be given. Should an application choose, it
can also supply additional metadata to allow advanced rendering
optimizations.

An issue that arose specifically in the VisIt integration
was state management in large, established software systems.
The OpenGL API is a global state machine, and VisIt
has many sub-libraries which can and will change the global
state in ways we cannot predict. Tuvok therefore makes very
few assumptions about OpenGL state. During the `setup'
stage, Tuvok takes state information---camera and viewing
reference points, data, etc.---and stores it locally.
A single method then uses all that information to configure
OpenGL state once before moving on to per-brick rendering.
For efficiency reasons, the system leaves the OpenGL
state `as-is' when finished rendering, much like other VisIt
subsystems and libraries do. Until OpenGL establishes an
object model, we have found this to be the best method for
managing OpenGL state.

\subsection{AltaViewer}

\begin{figure}
	\includegraphics[width=\linewidth]{images/arch/altaviewer}

	\caption{The left image shows an E11 mouse embryo
	(2.4GB) while the right image depicts a P0 newborn rat
	(7.6GB). Both specimens were stained using Numira's custom
	protocol and scanned using microCT. Images courtesy
	of Numira Biosciences. Copyright 2009 \copyright{} Numira Biosciences.
	All rights reserved. AltaViewer Software available
	at \url{http://www.numirabio.com/}}
	\label{fig:altaviewer}
\end{figure}

Finally, we demonstrate the usability of Tuvok's components
in a commercial environment. Numira Biosciences is a specialty
contract research organization (CRO) which focuses
on high-resolution imaging and analysis of small animal
specimens, provides researchers with quantifiable, visible
evidence of disease progression, as well as drug efficacy and
drug side effects in their animal models. For the next generation
of their visualization suite `AltaViewer' (see
Figure~\ref{fig:altaviewer}) they have chosen to replace their
proprietary IO library in part by Tuvok's IO components to achieve
significantly better performance.

\section{Conclusion and future work}

In this paper we have presented the Tuvok framework as well
as ImageVis3D, an application built with Tuvok. We gave insight
into large data support in a production volume renderer.
We also gave a couple of examples of research projects and
commercial use of components of Tuvok.
We are currently working on three major extensions to
Tuvok. First, the support of time dependent data sets, in
particular we are working to extend the progressive rendering
concept to this data as well. Secondly, we are extending
Tuvok to render multiple data sets in overlapping 3D space;
due to the out-of-core nature of the system an efficient
implementation of this feature is non-trivial. Finally, we also
plan to add purely software based as well as OpenCL based
ray casters to allow for fast rendering of ultra large data sets
on headless clusters with and without GPUs.
